{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":11574498,"sourceType":"datasetVersion","datasetId":7256817}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"script","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# %% [code] {\"execution\":{\"iopub.status.busy\":\"2025-09-10T20:14:45.595603Z\",\"iopub.execute_input\":\"2025-09-10T20:14:45.595846Z\",\"iopub.status.idle\":\"2025-09-10T20:14:45.608366Z\",\"shell.execute_reply.started\":\"2025-09-10T20:14:45.595828Z\",\"shell.execute_reply\":\"2025-09-10T20:14:45.607667Z\"}}\nimport h5py\n\nhdf_path = \"/kaggle/input/isp-ad-dataset/supervised_ASM/supervised_ASM/train/syn_train_asm.hdf5\"\n\nwith h5py.File(hdf_path, \"r\") as f:\n    print(\"Keys in file:\", list(f.keys()))\n    for k in f.keys():\n        print(f\"{k} -> shape: {f[k].shape}, dtype: {f[k].dtype}\")\n\n\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2025-09-10T22:30:10.549971Z\",\"iopub.execute_input\":\"2025-09-10T22:30:10.550617Z\",\"iopub.status.idle\":\"2025-09-10T23:57:26.044027Z\",\"shell.execute_reply.started\":\"2025-09-10T22:30:10.550591Z\",\"shell.execute_reply\":\"2025-09-10T23:57:26.042025Z\"}}\n# ================================\n# DeepLabV3 Training on ISP-AD ASM\n# ================================\n\nimport os, re, h5py, numpy as np\nimport torch, torch.nn as nn, torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader, random_split\nfrom torchvision import transforms\nimport torchvision.transforms.functional as TF\nimport torchvision.models.segmentation as models\nfrom PIL import Image\nimport matplotlib.pyplot as plt\n\n# ------------------\n# Dataset from HDF5\n# ------------------\nclass ISPADHDF5Dataset(Dataset):\n    def __init__(self, hdf5_path, image_size=(256,256)):\n        self.hdf5_path = hdf5_path\n        self.image_size = image_size\n        self.file = None  # will open lazily\n        self.normalize = transforms.Normalize(\n            mean=[0.485, 0.456, 0.406],\n            std=[0.229, 0.224, 0.225]\n        )\n        with h5py.File(self.hdf5_path, \"r\") as f:\n            self.n_samples = f[\"syn_stream\"].shape[0]\n\n    def __len__(self):\n        return self.n_samples\n\n    def __getitem__(self, idx):\n        if self.file is None:\n            self.file = h5py.File(self.hdf5_path, \"r\")\n            self.imgs = self.file[\"syn_stream\"]\n            self.masks = self.file[\"ground_truth\"]\n\n        img = self.imgs[idx][0]      # (256,256)\n        mask = self.masks[idx][0]    # (256,256), bool\n\n        img = Image.fromarray(img).convert(\"RGB\")\n        mask = Image.fromarray(mask.astype(np.uint8)*255)\n\n        img = img.resize(self.image_size)\n        mask = mask.resize(self.image_size)\n\n        img = TF.to_tensor(img)\n        img = self.normalize(img)\n        mask = torch.from_numpy(np.array(mask)).long() // 255\n\n        return img, mask\n\n# ------------------\n# Dataset from PNG\n# ------------------\nclass ISPADDataset(Dataset):\n    def __init__(self, image_dir, mask_dir, image_size=(256,256)):\n        self.image_dir = image_dir\n        self.mask_dir = mask_dir\n        self.image_size = image_size\n        self.files = sorted(set(os.listdir(image_dir)) & set(os.listdir(mask_dir)))\n        self.normalize = transforms.Normalize(\n            mean=[0.485, 0.456, 0.406],\n            std=[0.229, 0.224, 0.225]\n        )\n\n    def __len__(self):\n        return len(self.files)\n\n    def __getitem__(self, idx):\n        fname = self.files[idx]\n        img_path = os.path.join(self.image_dir, fname)\n        mask_path = os.path.join(self.mask_dir, fname)\n\n        image = Image.open(img_path).convert(\"RGB\")\n        mask  = Image.open(mask_path).convert(\"L\")\n\n        image = image.resize(self.image_size)\n        mask  = mask.resize(self.image_size)\n\n        image = TF.to_tensor(image)\n        image = self.normalize(image)\n        mask = torch.from_numpy(np.array(mask)).long() // 255\n\n        return image, mask\n\n# ------------------\n# Metrics\n# ------------------\ndef compute_iou(pred, target, num_classes=2):\n    pred = pred.view(-1)\n    target = target.view(-1)\n    ious = []\n    for cls in range(num_classes):\n        pred_inds = pred == cls\n        target_inds = target == cls\n        intersection = (pred_inds[target_inds]).sum().item()\n        union = pred_inds.sum().item() + target_inds.sum().item() - intersection\n        if union == 0:\n            ious.append(float(\"nan\"))\n        else:\n            ious.append(intersection / union)\n    return np.nanmean(ious)\n\ndef compute_dice(pred, target, smooth=1e-6):\n    pred = pred.view(-1)\n    target = target.view(-1)\n    intersection = (pred * target).sum().item()\n    return (2. * intersection + smooth) / (pred.sum().item() + target.sum().item() + smooth)\n\n# ------------------\n# Prepare Datasets\n# ------------------\nHDF_PATH = \"/kaggle/input/isp-ad-dataset/supervised_ASM/supervised_ASM/train/syn_train_asm.hdf5\"\nTRAIN_IMG_DIR = \"/kaggle/working/asm/train_images\"   # not used now\nTRAIN_MASK_DIR = \"/kaggle/working/asm/train_masks\"   # not used now\nTEST_IMG_DIR = \"/kaggle/working/asm/test_images\"\nTEST_MASK_DIR = \"/kaggle/working/asm/test_masks\"\n\n# train/val from HDF5\nfull_dataset = ISPADHDF5Dataset(HDF_PATH, image_size=(256,256))\nn = len(full_dataset)\nn_val = int(0.1 * n)\nn_train = n - n_val\ntrain_dataset, val_dataset = random_split(full_dataset, [n_train, n_val])\n\nfrom torch.utils.data import Subset\n\n# Optional: reduce train set for quicker runs\nTRAIN_SUBSET_SIZE = 20000   # set None for full dataset\n\nif TRAIN_SUBSET_SIZE is not None and TRAIN_SUBSET_SIZE < len(train_dataset):\n    idx = torch.randperm(len(train_dataset))[:TRAIN_SUBSET_SIZE].tolist()\n    train_dataset = Subset(train_dataset, idx)\n    print(f\"âš¡ Using subset of train: {len(train_dataset)} samples\")\n\n\ntrain_loader = DataLoader(train_dataset, batch_size=16, shuffle=True, num_workers=2)\nval_loader   = DataLoader(val_dataset, batch_size=16, shuffle=False, num_workers=2)\n\n# test from PNG\ntest_dataset = ISPADDataset(TEST_IMG_DIR, TEST_MASK_DIR, image_size=(256,256))\ntest_loader = DataLoader(test_dataset, batch_size=16, shuffle=False, num_workers=2)\n\nprint(f\"Train: {len(train_dataset)}, Val: {len(val_dataset)}, Test: {len(test_dataset)}\")\n\n# ------------------\n# Model\n# ------------------\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Using device:\", device)\n\nmodel = models.deeplabv3_resnet101(weights=None, num_classes=2)\nmodel = model.to(device)\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=1e-4)\n\n# ------------------\n# Training\n# ------------------\nfrom pathlib import Path\nimport matplotlib.pyplot as plt\n\nnum_epochs = 2\nsave_dir = Path(\"/kaggle/working/checkpoints\")\nsave_dir.mkdir(parents=True, exist_ok=True)\n\nbest_val_iou = 0.0\n\nfor epoch in range(num_epochs):\n    # --- Train ---\n    model.train()\n    train_loss = 0\n    for imgs, masks in train_loader:\n        imgs, masks = imgs.to(device), masks.to(device)\n        optimizer.zero_grad()\n        outputs = model(imgs)['out']\n        loss = criterion(outputs, masks)\n        loss.backward()\n        optimizer.step()\n        train_loss += loss.item()\n\n    # --- Validate ---\n    model.eval()\n    val_loss = 0\n    val_ious, val_dices = [], []\n    with torch.no_grad():\n        for imgs, masks in val_loader:\n            imgs, masks = imgs.to(device), masks.to(device)\n            outputs = model(imgs)['out']\n            loss = criterion(outputs, masks)\n            val_loss += loss.item()\n\n            preds = outputs.argmax(1)\n            val_ious.append(compute_iou(preds.cpu(), masks.cpu()))\n            val_dices.append(compute_dice((preds>0).cpu(), (masks>0).cpu()))\n\n    avg_train_loss = train_loss / len(train_loader)\n    avg_val_loss = val_loss / len(val_loader)\n    avg_val_iou = np.nanmean(val_ious)\n    avg_val_dice = np.nanmean(val_dices)\n\n    print(f\"Epoch {epoch+1}/{num_epochs} \"\n          f\"Train Loss: {avg_train_loss:.4f} \"\n          f\"Val Loss: {avg_val_loss:.4f} \"\n          f\"IoU: {avg_val_iou:.4f} \"\n          f\"Dice: {avg_val_dice:.4f}\")\n\n    # --- Save checkpoint ---\n    ckpt_path = save_dir / f\"epoch_{epoch+1}.pth\"\n    torch.save(model.state_dict(), ckpt_path)\n    print(f\"ðŸ’¾ Saved checkpoint: {ckpt_path}\")\n\n    # --- Save best model ---\n    if avg_val_iou > best_val_iou:\n        best_val_iou = avg_val_iou\n        torch.save(model.state_dict(), \"best_deeplabv3.pth\")\n        print(\"âœ… Updated best model\")\n\n    # --- Visualization on test samples ---\n    model.eval()\n    imgs, masks = next(iter(test_loader))\n    with torch.no_grad():\n        outputs = model(imgs.to(device))['out']\n        preds = outputs.argmax(1).cpu()\n\n    plt.figure(figsize=(12, 6))\n    for i in range(3):\n        plt.subplot(3, 3, i*3+1)\n        plt.imshow(imgs[i].permute(1,2,0))\n        plt.title(\"Image\")\n        plt.axis(\"off\")\n\n        plt.subplot(3, 3, i*3+2)\n        plt.imshow(masks[i])\n        plt.title(\"Ground Truth\")\n        plt.axis(\"off\")\n\n        plt.subplot(3, 3, i*3+3)\n        plt.imshow(preds[i])\n        plt.title(\"Prediction\")\n        plt.axis(\"off\")\n    plt.suptitle(f\"Sample Predictions - Epoch {epoch+1}\", fontsize=14)\n    plt.show()\n\n\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2025-09-10T22:00:33.763086Z\",\"iopub.execute_input\":\"2025-09-10T22:00:33.763841Z\",\"iopub.status.idle\":\"2025-09-10T22:01:20.856273Z\",\"shell.execute_reply.started\":\"2025-09-10T22:00:33.763813Z\",\"shell.execute_reply\":\"2025-09-10T22:01:20.855631Z\"}}\nimport os, re\nimport numpy as np\nfrom pathlib import Path\nfrom PIL import Image\nfrom tqdm import tqdm\n\n# --- input paths ---\nASM_TEST_ROOT = \"/kaggle/input/isp-ad-dataset/supervised_ASM/supervised_ASM/test\"\nDEFECT_DIR = os.path.join(ASM_TEST_ROOT, \"defects\")\nGOOD_DIR   = os.path.join(ASM_TEST_ROOT, \"good\")\n\n# --- output paths ---\nOUT_TEST_IMG  = Path(\"/kaggle/working/asm/test_images\")\nOUT_TEST_MASK = Path(\"/kaggle/working/asm/test_masks\")\nOUT_TEST_IMG.mkdir(parents=True, exist_ok=True)\nOUT_TEST_MASK.mkdir(parents=True, exist_ok=True)\n\n# --- helper: extract numeric ID from filename ---\ndef get_id(fname):\n    m = re.match(r\"^(\\d+)\", fname)\n    return int(m.group(1)) if m else None\n\n# --- process defect cases ---\ndefect_masks = [f for f in os.listdir(DEFECT_DIR) if f.endswith(\".png\") and \"_area_\" in f]\nfor f in tqdm(defect_masks, desc=\"Processing defect cases\"):\n    base_id = get_id(f)\n    if base_id is None:\n        continue\n\n    # save mask (binary)\n    mask_path = os.path.join(DEFECT_DIR, f)\n    mask = Image.open(mask_path).convert(\"L\")\n    mnp = (np.array(mask) > 0).astype(np.uint8) * 255\n    Image.fromarray(mnp).save(OUT_TEST_MASK / f\"{base_id:06d}.png\")\n\n    # matching image should exist as \"{id}.png\" or \"{id}_defect_asm.png\"\n    candidates = [\n        os.path.join(DEFECT_DIR, f\"{base_id}.png\"),\n        os.path.join(DEFECT_DIR, f\"{base_id}_defect_asm.png\"),\n    ]\n    img_path = None\n    for c in candidates:\n        if os.path.exists(c):\n            img_path = c\n            break\n    if img_path is None:\n        print(f\"âš ï¸ No matching defect image for {f}\")\n        continue\n\n    img = Image.open(img_path).convert(\"RGB\")\n    img.save(OUT_TEST_IMG / f\"{base_id:06d}.png\")\n\n# --- process good cases ---\ngood_imgs = [f for f in os.listdir(GOOD_DIR) if f.endswith(\".png\")]\nfor f in tqdm(good_imgs, desc=\"Processing good cases\"):\n    base_id = get_id(f)\n    if base_id is None:\n        continue\n\n    # save image\n    img = Image.open(os.path.join(GOOD_DIR, f)).convert(\"RGB\")\n    img.save(OUT_TEST_IMG / f\"{base_id:06d}.png\")\n\n    # zero mask\n    mask = np.zeros((img.size[1], img.size[0]), dtype=np.uint8)\n    Image.fromarray(mask).save(OUT_TEST_MASK / f\"{base_id:06d}.png\")\n\nprint(\"âœ… Test set prepared\")\nprint(\"Images:\", len(os.listdir(OUT_TEST_IMG)))\nprint(\"Masks :\", len(os.listdir(OUT_TEST_MASK)))\n\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2025-09-10T22:03:34.554930Z\",\"iopub.execute_input\":\"2025-09-10T22:03:34.555468Z\",\"iopub.status.idle\":\"2025-09-10T22:03:35.337852Z\",\"shell.execute_reply.started\":\"2025-09-10T22:03:34.555441Z\",\"shell.execute_reply\":\"2025-09-10T22:03:35.337257Z\"}}\nimport h5py, numpy as np, os, re\nfrom pathlib import Path\nfrom PIL import Image\nfrom tqdm import tqdm\n\n# --- config ---\nASM_ROOT = \"/kaggle/input/isp-ad-dataset/supervised_ASM/supervised_ASM\"\nHDF_PATH = f\"{ASM_ROOT}/train/syn_train_asm.hdf5\"\nMASK_DIR = f\"{ASM_ROOT}/train/defects\"   # contains *_area_asm.png\n\nOUT_IMG_DIR  = Path(\"/kaggle/working/asm/train_images\")\nOUT_MASK_DIR = Path(\"/kaggle/working/asm/train_masks\")\nOUT_IMG_DIR.mkdir(parents=True, exist_ok=True)\nOUT_MASK_DIR.mkdir(parents=True, exist_ok=True)\n\n# --- collect available area masks (only *_area_asm.png) ---\narea_files = [f for f in os.listdir(MASK_DIR) if f.endswith(\".png\") and \"_area_\" in f]\nid_pat = re.compile(r\"^(\\d+)_\")\nids = []\nfor f in area_files:\n    m = id_pat.match(f)\n    if m: ids.append(int(m.group(1)))\nids = sorted(set(ids))\n\nprint(f\"Found {len(ids)} area masks\")\n\n# --- export matching images from HDF5 ---\nwith h5py.File(HDF_PATH, \"r\") as f:\n    imgs = f[\"syn_stream\"]       # grayscale images\n    N = len(imgs)\n    missing = []\n    for i in tqdm(ids, desc=\"Exporting images\"):\n        if i >= N:\n            missing.append(i)\n            continue\n        arr = imgs[i][0]                         # shape (256,256)\n        Image.fromarray(arr).convert(\"L\").save(OUT_IMG_DIR / f\"{i:06d}.png\")\n\nprint(f\"Exported {len(ids)-len(missing)} images to {OUT_IMG_DIR}\")\nif missing:\n    print(f\"âš ï¸ Missing {len(missing)} image IDs, e.g. {missing[:5]}\")\n\n# --- copy & normalize masks ---\ncopied = 0\nfor f in area_files:\n    m = id_pat.match(f)\n    if not m: continue\n    i = int(m.group(1))\n    src = Path(MASK_DIR) / f\n    dst = OUT_MASK_DIR / f\"{i:06d}.png\"\n\n    mask = Image.open(src).convert(\"L\")\n    mnp = np.array(mask)\n    mnp = (mnp > 0).astype(np.uint8) * 255  # binarize\n    Image.fromarray(mnp).save(dst)\n    copied += 1\n\nprint(f\"Copied {copied} masks to {OUT_MASK_DIR}\")\n\n# --- sanity check ---\nimg_names = set(os.listdir(OUT_IMG_DIR))\nmsk_names = set(os.listdir(OUT_MASK_DIR))\npairs = sorted(img_names & msk_names)\nprint(f\"âœ… Paired samples: {len(pairs)}\")\nprint(\"Sample pair:\", pairs[:5])\n\n\n# %% [markdown]\n# \n# * loads the ASM synthetic training set directly from HDF5 (syn_train_asm.hdf5)\n# * Splits it into train/valUses\n# * the PNG-based test set we prepared earlier (test_images/, test_masks/)\n# * Trains a DeepLabV3 (ResNet101)\n# * modelEvaluates with IoU and Dice metrics\n# * Saves the best model\n# ","metadata":{"_uuid":"00dfe754-5049-4d46-a64a-ff51967d9e48","_cell_guid":"18019c19-5596-4eb8-907f-ab4f8c2d3230","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null}]}